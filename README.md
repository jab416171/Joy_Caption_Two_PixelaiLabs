# Joy Caption Two - PixelaiLabs Edition

<div align="center">

**Automated Image Captioning for ComfyUI with Joy Caption Alpha Two**

[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)
[![ComfyUI](https://img.shields.io/badge/ComfyUI-Custom%20Node-orange)](https://github.com/comfyanonymous/ComfyUI)

**Created by [PixelaiLabs.com](https://pixelailabs.com) | [@aiconomist](https://youtube.com/@aiconomist)**

[Installation](#installation) ‚Ä¢ [Features](#features) ‚Ä¢ [Usage](#usage) ‚Ä¢ [License](#license)

</div>


## üîî Latest Updates

### February 2026 - Remote Joy Caption Server
- ‚úÖ **Full Remote Pipeline** - Run complete Joy Caption (vision + LLM) on remote servers
- ‚úÖ **Identical Quality** - Remote mode maintains full vision capabilities
- ‚úÖ **VRAM Optimization** - Offload everything to powerful remote machines
- ‚úÖ **Easy Setup** - Simple Flask-based server included
- üéØ **Perfect for distributed setups** - Share GPU servers across multiple workstations

### November 6, 2025 - VRAM Management Update
- ‚úÖ **Automatic VRAM Management** - Models now automatically unload from VRAM after each caption generation
- ‚úÖ **Smart Reloading** - Models reload to GPU only when needed for the next caption
- ‚úÖ **Frees ~10GB VRAM** - VRAM is released between caption generations, preventing memory buildup
- ‚úÖ **No Manual Intervention** - Everything happens automatically in the background
- üéØ **Perfect for batch processing** - Process large datasets without running out of memory

---

## üåü What is This?

A **fully automated** ComfyUI custom node that uses **Joy Caption Alpha Two** to generate high-quality image captions. Perfect for:
- LoRA/model training dataset preparation
- Image tagging and organization
- NSFW content captioning
- Batch processing large image collections

### Why This Version?

- ‚úÖ **100% Automated** - All models download automatically on first use
- ‚úÖ **Joy Caption Quality** - Uses the exact same LoRA adapter and process as the original
- ‚úÖ **Clean Output** - No "Here is a caption:" prefixes or numbered lists
- ‚úÖ **Training Ready** - Batch node outputs chronologically numbered files (1.png, 1.txt, 2.png, 2.txt, ...)
- ‚úÖ **Easy Setup** - Just install requirements and run!

---

## üì¶ Installation

### Step 1: Clone the Repository

```bash
cd ComfyUI/custom_nodes
git clone https://github.com/Pixelailabs/Joy_Caption_Two_PixelaiLabs.git
```

### Step 2: Install Requirements

```bash
cd Joy_Caption_Two_PixelaiLabs
pip install -r requirements.txt
```

### Step 3: Restart ComfyUI

That's it! On first use, the node will automatically download:
- **SigLIP vision model** (~1.5GB)
- **Joy Caption adapters** (~2.5GB total):
  - Image adapter (86 MB)
  - Custom CLIP weights (1.71 GB)
  - LoRA adapter (671 MB) - *This ensures clean caption output!*
- **Your chosen LLM** (~4-5GB when you select it)

**Total first-time download: ~6-8GB** (one-time only!)

---

## ‚ú® Features

| Feature | Description |
|---------|-------------|
| **Joy Caption LoRA** | Uses the official 671MB LoRA adapter for professional captions |
| **NSFW Capable** | Handles adult content with image embeddings (LLM truly "sees" the image) |
| **Automated Setup** | All models download automatically - no manual file placement |
| **Multiple Caption Styles** | Descriptive, Training Prompt, Booru Tags, Art Critic, etc. |
| **Adjustable Length** | From very short to very long captions |
| **Text Processing** | Replace gender/age, hair, body type, remove tattoos/jewelry |
| **Batch Processing** | Process entire folders with chronological naming for training |
| **Dual Outputs** | Advanced node outputs positive + negative prompts |
| **Remote Server Support** | Run complete pipeline on remote servers with full vision capability |

---

## üåê Remote Joy Caption Server

**NEW: Offload the entire Joy Caption pipeline to a remote server!**

This feature allows you to run the complete vision + LLM pipeline on a separate server (e.g., a more powerful machine or cloud instance), maintaining **FULL vision capabilities and caption quality**.

### ‚úÖ Full Vision Support

Unlike basic llama.cpp servers, our remote solution runs the **COMPLETE Joy Caption pipeline**:
- ‚úÖ **SigLIP Vision Processing** - Image understanding happens on remote server
- ‚úÖ **Image Adapter** - Vision-to-language translation on remote server
- ‚úÖ **LLM with LoRA** - Caption generation with full visual context
- ‚úÖ **Identical Quality** - Remote mode produces the SAME high-quality output as local mode

### Setting Up Remote Server

1. **On your remote server** (GPU machine, cloud instance, etc.):
   ```bash
   cd Joy_Caption_Two_PixelaiLabs
   pip install -r requirements.txt
   python joy_caption_server.py --host 0.0.0.0 --port 8000 --model "Llama-3.1-8B-Lexi-Uncensored-V2-nf4"
   ```

2. **On your ComfyUI client** machine:
   - Add "Simple LLM Caption Loader" node
   - Enable `use_remote_server` checkbox
   - Set `remote_server_url` to your server (e.g., `http://192.168.1.100:8000`)
   - Connect and generate captions!

### Benefits of Remote Mode

- üöÄ **Offload GPU Work** - Free up local VRAM completely (vision + LLM run remotely)
- ‚ö° **Powerful Hardware** - Use cloud GPUs or dedicated servers
- üîÑ **Multi-User** - Multiple ComfyUI instances can share one server
- üí∞ **Cost Effective** - Rent GPU instances only when needed
- üì° **Network Efficiency** - Only images and captions are transmitted (not embeddings)

### Server API

The Joy Caption Server provides a simple REST API:

**POST /caption**
```json
{
  "image": "base64_encoded_image_data",
  "caption_type": "Descriptive",
  "caption_length": "medium-length",
  "lora_trigger": "",
  ...
}
```

**Response**
```json
{
  "success": true,
  "caption": "A young woman with long blonde hair..."
}
```

---
---

## üöÄ Usage

### Basic Workflow

```
[Load Image] ‚Üí [Simple LLM Caption Loader] ‚Üí [Simple LLM Caption] ‚Üí [Save Text]
                                                      ‚Üì
                                                  Caption Text
```

1. **Add "Simple LLM Caption Loader" node**
   - Select LLM: "AUTO-DOWNLOAD: Llama-3.1-8B-Lexi-Uncensored-V2-nf4" (recommended)
   - Models download automatically on first run

2. **Add "Simple LLM Caption" node**
   - Connect pipeline from loader
   - Connect your image
   - Choose caption type and length
   - Optional: Add LoRA trigger, text replacements

3. **Output:** Clean caption text ready to use!

### Batch Processing for Training

Perfect for preparing LoRA/model training datasets:

```
[Simple LLM Caption Loader] ‚Üí [Simple LLM Caption Batch]
                                       ‚Üì
                              Chronologically numbered files
```

**Input folder:**
```
my_photos/
  ‚îú‚îÄ‚îÄ photo1.jpg
  ‚îú‚îÄ‚îÄ image_abc.png
  ‚îî‚îÄ‚îÄ IMG_5678.jpg
```

**Output folder:**
```
training_data/
  ‚îú‚îÄ‚îÄ 1.png  ‚Üê photo1.jpg converted
  ‚îú‚îÄ‚îÄ 1.txt  ‚Üê caption for 1.png
  ‚îú‚îÄ‚îÄ 2.png  ‚Üê image_abc.png converted
  ‚îú‚îÄ‚îÄ 2.txt  ‚Üê caption for 2.png
  ‚îú‚îÄ‚îÄ 3.png  ‚Üê IMG_5678.jpg converted
  ‚îî‚îÄ‚îÄ 3.txt  ‚Üê caption for 3.png
```

Ready to use with Kohya, aitoolkit, or any training tool!

---

## üé® Caption Types

| Type | Description |
|------|-------------|
| **Descriptive** | Formal, detailed description |
| **Descriptive (Informal)** | Casual, conversational description |
| **Training Prompt** | Stable Diffusion style prompt |
| **MidJourney** | MidJourney style prompt |
| **Booru Tags** | Tag list (Danbooru/Gelbooru format) |
| **Art Critic** | Detailed analysis of composition and style |
| **Social Media** | Engaging caption for social posts |

---

## ‚öôÔ∏è Nodes

### 1. Simple LLM Caption Loader
Loads the LLM and Joy Caption adapter models (local or remote).

**Parameters:**
- `llm_model` - Choose from dropdown (AUTO-DOWNLOAD options shown first)
  - Recommended: "AUTO-DOWNLOAD: Llama-3.1-8B-Lexi-Uncensored-V2-nf4"
  - Only shows Llama-based models (Joy Caption compatible)
  - Automatically filters out incompatible models (Florence, CLIP, etc.)
- `use_4bit` - Enable 4-bit quantization (recommended for 8GB VRAM, local mode only)
- `use_remote_server` - Enable remote Joy Caption server mode (optional)
- `remote_server_url` - URL of remote Joy Caption server (default: http://localhost:8000)

**Note:** Vision model (SigLIP) downloads automatically in local mode - no selection needed!

### 2. Simple LLM Caption
Generate captions for single images.

**Parameters:**
- `caption_type` - Style of caption
- `caption_length` - Target length (any, short, medium, long, very long)
- `lora_trigger` - Text to prepend to caption
- Text replacements (gender/age, hair, body size)
- Filters (remove tattoos, remove jewelry)

**Output:** `STRING` (caption text)

### 3. Simple LLM Caption Advanced
Advanced options with positive/negative prompt outputs.

**Additional Parameters:**
- `temperature` / `top_p` - Control randomness
- `max_new_tokens` - Maximum caption length
- `append_to_caption` - Text to add at END of caption
- `negative_prompt` - Manual negative prompt input

**Outputs:** 
- `positive_prompt` (STRING) - Final caption
- `negative_prompt` (STRING) - Your negative prompt

### 4. Simple LLM Caption Batch
Batch process folders with chronological naming for training.

**Parameters:**
- `input_directory` - Folder with images
- `output_directory` - Where to save (REQUIRED)
- All caption options from basic node

**Output:** Status message

---

## üîß System Requirements

| Requirement | Minimum | Recommended |
|-------------|---------|-------------|
| **VRAM** | 8GB (with 4-bit) | 12GB+ |
| **RAM** | 16GB | 32GB+ |
| **Storage** | 10GB free | 20GB+ free |
| **Python** | 3.10+ | 3.11 |

---

## üìñ Credits & Attribution

This custom node is built using:

### Core Technology
- **[Joy Caption](https://github.com/fpgaminer/joycaption)** by fpgaminer - Original Joy Caption implementation
- **[Joy Caption Alpha Two](https://huggingface.co/spaces/fancyfeast/joy-caption-alpha-two)** by fancyfeast - LoRA adapter and training

### Inspiration
- **[ComfyUI_SLK_joy_caption_two](https://github.com/EvilBT/ComfyUI_SLK_joy_caption_two)** by EvilBT - ComfyUI implementation reference

### Models Used
- **SigLIP** by Google - Vision backbone
- **Llama 3.1** by Meta - Language model

---

## üìÑ License

This project is licensed under the **GNU General Public License v3.0** - see the [LICENSE](LICENSE) file for details.

**Important Notes:**
- This is a derivative work based on Joy Caption Alpha Two (GPL-3.0)
- Commercial use is allowed under GPL-3.0 terms
- Any modifications must also be released under GPL-3.0
- Please provide attribution when using or modifying this code

---

## ü§ù Support

- **Issues:** [GitHub Issues](https://github.com/YOUR_USERNAME/Joy_Caption_Two_PixelaiLabs/issues)
- **YouTube:** [@aiconomist](https://youtube.com/@aiconomist)
- **Website:** [PixelaiLabs.com](https://pixelailabs.com)

---

## üéØ Roadmap

- [ ] Support for more LLM models
- [ ] Custom LoRA adapter training
- [ ] Multi-language captions
- [ ] Video frame captioning

---

<div align="center">

**Made with ‚ù§Ô∏è by [PixelaiLabs.com](https://pixelailabs.com)**

If you find this useful, please ‚≠ê star the repository!

</div>
